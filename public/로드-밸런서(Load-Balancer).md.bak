특정 상품의 할인 판매 시작, 인기 아이돌의 콘서트 티켓 예매. 분명 시작 시간은 10시인데, 10시가 되자마자 웹사이트가 멈추거나 접속이 되지 않는 경험을 해보신 적이 있으신가요? 이런 현상은 한순간에 너무 많은 사용자가 몰려 서버가 감당할 수 있는 트래픽의 양을 초과했기 때문에 발생합니다.

가장 단순한 해결책은 더 좋은 성능의 서버로 교체하는 것([[Scale-up]])이지만, 이 방법은 비용이 많이 들고 성능 향상에 명확한 한계가 있습니다. 그래서 대부분의 현대적인 웹 서비스는 여러 대의 서버를 두고 작업을 나누어 처리하는 [[Scale-out]] 방식을 사용합니다.

이때, 새로운 문제가 발생합니다. "수많은 사용자의 요청을 여러 대의 서버에 어떻게 효율적으로, 그리고 공평하게 나누어 줄 것인가?" 이 질문에 대한 해답이 바로 **로드 밸런서(Load Balancer)**입니다. 로드 밸런서는 말 그대로 서버가 처리해야 할 **부하(Load)를 분산(Balancing)시켜주는** 장치 또는 기술을 의미합니다. 서버들의 '교통 경찰'과 같은 역할을 수행하는 것이죠.

---

## 로드 밸런서의 핵심 역할과 필요성

로드 밸런서는 여러 대의 서버 그룹 가장 앞단에 위치하여, 클라이언트로부터 들어오는 모든 요청을 일단 받은 뒤, 이를 가장 적절한 서버에 분배해주는 역할을 합니다.


```mermaid
graph TD
    subgraph Clients
        User1[<i class="fa fa-user"></i> 사용자 1]
        User2[<i class="fa fa-user"></i> 사용자 2]
        User3[<i class="fa fa-user"></i> 사용자 3]
    end

    subgraph "로드 밸런서"
        LB(Load Balancer)
    end

    subgraph "서버 그룹"
        Server1[서버 1]
        Server2[서버 2]
        Server3[<font color=red>서버 3 장애</font>]
    end

    User1 -- 요청 --> LB
    User2 -- 요청 --> LB
    User3 -- 요청 --> LB

    LB -- 분산 --> Server1
    LB -- 분산 --> Server2
    LB -- 장애 감지 후 트래픽 차단 --> Server3

    style Server3 stroke:#ff0000,stroke-width:2px,stroke-dasharray: 5 5
```

이 간단한 구조를 통해 우리는 다음과 같은 핵심적인 이점을 얻을 수 있습니다.

1. **[[고가용성(High Availability)]]**: 위 그림처럼 서버 한 대에 장애가 발생하더라도, 로드 밸런서가 이를 감지하고 정상적으로 동작하는 다른 서버로만 요청을 보내 서비스가 중단되는 것을 막습니다. 이 장애 감지 기능을 [[Health Check]]라고 부릅니다.
2. **[[확장성 (Scalability)]]**: 서비스의 트래픽이 증가하면, 새로운 서버를 추가하고 로드 밸런서의 분배 대상에 포함시키기만 하면 됩니다. 반대로 트래픽이 줄면 서버를 줄여 비용을 절감할 수 있습니다. 이러한 유연한 확장이 가능해집니다.
3. **성능 및 안정성**: 모든 요청이 특정 서버 하나에 집중되지 않고 여러 서버로 분산되므로, 각 서버의 부하가 줄어들어 전체적인 서비스 응답 속도가 향상되고 안정성이 높아집니다.

---

## 로드 밸런서의 종류: L4와 L7

로드 밸런서는 네트워크 OSI 7계층 중 주로 4계층(Transport Layer)과 7계층(Application Layer)에서 동작하며, 이에 따라 크게 L4와 L7 로드 밸런서로 나뉩니다.

### 1. L4 로드 밸런서

- **동작 계층**: 전송 계층 (Transport Layer)
- **분산 기준**: 패킷의 **IP 주소** 및 **포트 번호**
- **특징**: 패킷의 내용(데이터)을 들여다보지 않고, 오직 주소 정보만을 보고 트래픽을 분산합니다. 따라서 처리 속도가 매우 빠르다는 장점이 있습니다. 대표적인 L4 프로토콜로는 TCP, UDP가 있습니다.

### 2. L7 로드 밸런서

- **동작 계층**: 응용 계층 (Application Layer)
- **분산 기준**: 요청의 실제 내용 (HTTP 헤더, URL, 쿠키 등)
- **특징**: 데이터의 내용까지 분석하여 분산 처리가 가능합니다. 예를 들어, `/images` 라는 경로의 요청은 이미지 처리 전용 서버로, `/video` 요청은 동영상 서버로 보내는 등 훨씬 정교하고 지능적인 라우팅을 할 수 있습니다. 하지만 내용을 분석하는 과정 때문에 L4에 비해 약간의 처리 시간이 더 소요될 수 있습니다.

서비스의 특성에 따라 적절한 종류의 로드 밸런서를 선택하는 것이 중요합니다. 더 자세한 비교는 [[L4 vs L7 로드 밸런서 비교]] 문서를 참고해주세요.

---

## 부하 분산 방법: 로드 밸런싱 알고리즘

로드 밸런서가 "어떤 서버로 요청을 보낼지" 결정하는 규칙을 **로드 밸런싱 알고리즘**이라고 합니다. 다양한 알고리즘이 있으며, 대표적인 몇 가지는 다음과 같습니다.

- **라운드 로빈 (Round Robin)**: 서버들에게 순서대로 돌아가며 요청을 분배하는 가장 단순하고 일반적인 방식입니다.
- **최소 연결 (Least Connections)**: 현재 연결(세션) 수가 가장 적은 서버에게 다음 요청을 보내는 방식입니다. 각 서버의 처리 능력이 비슷하지만, 요청마다 처리 시간이 다를 때 효과적입니다.
- **IP 해시 (IP Hash)**: 클라이언트의 IP 주소를 해싱(Hashing)하여 특정 서버로만 요청을 보내는 방식입니다. 사용자가 항상 같은 서버에 접속해야 하는 [[세션 지속성(Session Persistence)]]이 필요할 때 유용합니다.

이 외에도 다양한 알고리즘이 있으며, 각각의 장단점을 이해하고 상황에 맞게 선택해야 합니다. 자세한 내용은 [[로드 밸런싱 알고리즘]] 노트에서 확인하실 수 있습니다.

---

## 하드웨어 vs 소프트웨어 로드 밸런서

로드 밸런서는 물리적인 장비 형태의 **하드웨어 로드 밸런서**와, 일반 서버에 설치하여 사용하는 **소프트웨어 로드 밸런서**로 나눌 수 있습니다.

- **하드웨어 로드 밸런서**: 전용 장비로, 매우 높은 성능과 안정성을 제공하지만 가격이 비싸고 유연성이 떨어질 수 있습니다. (예: F5의 BIG-IP)
- **소프트웨어 로드 밸런서**: 애플리케이션 형태로 제공되며, 유연하고 비용 효율적입니다. 클라우드 환경에서 널리 사용됩니다. (예: [[HAProxy]], Nginx, AWS의 ALB/NLB)

---

## 결론

로드 밸런서는 더 이상 선택이 아닌, 안정적이고 확장 가능한 현대 웹 서비스를 구축하기 위한 필수 구성 요소입니다. 단순히 트래픽을 나누는 것을 넘어, 장애를 극복하고, 유연하게 확장하며, 사용자에게 최적의 성능을 제공하는 핵심적인 역할을 담당합니다.

우리가 안정적으로 웹 서비스를 이용할 수 있는 배경에는, 보이지 않는 곳에서 묵묵히 트래픽을 지휘하고 있는 로드 밸런서의 역할이 크다는 것을 기억해주시기 바랍니다.