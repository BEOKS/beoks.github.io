최근 Twitter에서 Google DeepMind가 발표한 새로운 논문 하나를 접하게 되었습니다. 읽어보니 올해 AI 에이전트 분야에서 가장 중요한 내용이 될 것 같아, 깊이 분석해 보려고 합니다.

[[AI 에이전트(AI Agent)|AI 에이전트]]가 단순한 질의-응답을 넘어 복잡한 작업을 자율적으로 수행하는 시대가 열리고 있습니다. 하지만 하나의 에이전트가 모든 것을 처리할 수는 없습니다. 복잡한 목표를 달성하려면, 작업을 분해하고 다른 AI 에이전트나 인간에게 위임(delegation)할 수 있어야 합니다. 그런데 현재의 멀티 에이전트 시스템은 단순한 [[휴리스틱(Heuristic)|휴리스틱]]에 의존하고 있어, 환경 변화에 동적으로 적응하거나 예상치 못한 실패를 처리하는 데 한계가 있습니다.

2026년 2월, Google DeepMind의 Nenad Tomasev, Matija Franklin, Simon Osindero는 이 문제를 정면으로 다루는 논문 "Intelligent AI Delegation"을 발표했습니다. 이 논문은 AI 에이전트 간의 작업 위임을 위한 포괄적인 프레임워크를 제안하며, 단순한 작업 분배를 넘어 권한 이전, 책임, 책무성[^accountability], 신뢰 구축까지 아우르는 체계를 설계합니다.

[^accountability]: **책무성**(責務性, Accountability)은 단순히 맡은 일을 수행하는 '책임(Responsibility)'과 구별되는 개념으로, 수행 결과에 대해 설명하고 답변할 의무, 즉 결과에 대해 추궁당할 수 있는 상태를 의미합니다. AI 위임 맥락에서는 감사 추적(audit trail), 암호학적 서명, 검증 가능한 작업 완료 메커니즘을 통해 기술적으로 강제됩니다.

이 글에서는 개발자의 시선으로 이 논문의 핵심 내용을 빠짐없이 분석하고, 우리가 구축하는 시스템에 어떤 시사점을 주는지 살펴보겠습니다.

> 이 논문은 내용 하나하나가 굉장히 추상적이고 복잡합니다. 각 개념의 의미와 세부적인 내용을 좀 더 깊이 이해할 수 있도록 별도의 문서로 정리해 두었으니, 본문 중 링크가 걸린 용어들을 따라가며 읽어보시는 것을 추천드립니다.

---

## 1. 왜 "지능형 위임"인가?

### 위임은 단순한 작업 분배가 아니다

우리가 흔히 사용하는 멀티 에이전트 시스템에서의 작업 분배는 사실 위임의 축소판에 불과합니다. 하드코딩된 제어 흐름 안에서 sub-agent에게 작업을 나누는 것은, 동적인 웹 규모의 상호작용을 관리하기에 턱없이 부족합니다.

논문은 **지능형 위임(Intelligent Delegation)** 을 다음과 같이 정의합니다:

> 작업 할당을 포함하는 일련의 의사결정으로서, **권한의 이전**, **책임**, **책무성**, 역할과 경계에 관한 **명확한 명세**, **의도의 명료성**, 그리고 당사자 간 **신뢰를 구축하기 위한 메커니즘**을 포괄한다.

이 정의는 위임의 범위가 하나의 스펙트럼 위에 있음을 시사합니다. 한쪽 끝에는 시스템 서브루틴이 처리하는 기초적 작업 위탁이 있고, 다른 쪽 끝에는 에이전트에게 완전한 자율성을 부여하여 하위 목표를 자유롭게 추구하도록 하는 개방형 위임이 있습니다. 극단적 경우, 완전 자율 에이전트는 도덕적 판단까지 위임받게 되지만, 현재의 AI 에이전트는 이러한 판단에 참여할 역량이 심각하게 부족합니다.

진정한 위임(delegation)이란 다음을 포함합니다:

- 책임과 권한의 할당: 누가 무엇을 할 수 있고, 그 결과에 대해 누가 책임지는가
- 위험 평가와 신뢰 조절: 수임자를 얼마나 신뢰할 수 있는가
- 역량 매칭: 이 작업에 가장 적합한 수임자는 누구인가
- 지속적 모니터링과 동적 조정: 실행 중 문제가 생기면 어떻게 대응하는가
- 제약 조건 하에서의 작업 완수 보장: 지정된 경계 안에서 목표를 달성하는가

### 세 가지 위임 시나리오

위임은 위임자(delegator)와 수임자(delegatee)가 누구인지에 따라 세 가지로 나뉩니다:

1. 인간 → AI 에이전트: 가장 많이 논의된 형태. 개인 비서, 기업 자동화 등.
2. AI 에이전트 → AI 에이전트: 에이전트 경제가 성장하면서 점점 중요해지는 형태. orchestrator가 sub-agent에게 작업을 배분하는 계층적 위임과, 동등한 peer 간의 비계층적 위임이 모두 가능.
3. AI 에이전트 → 인간: 승차 공유 플랫폼의 algorithmic management처럼 이미 현실에 존재. 다만, 현재의 AI-인간 위임은 인간의 복지나 장기적 사회적 외부효과를 충분히 고려하지 못하고 있다는 문제가 있음.

---

## 2. 위임의 다차원적 속성

논문은 위임을 분석하기 위한 일곱 가지 축(axis)을 정의합니다. 이 축들은 모두 동등한 수준에서 위임의 성격을 결정하는 차원들입니다.

### 축 1·2: 위임자(Delegator)와 수임자(Delegatee)

가장 기본적인 두 축은 **누가 위임하고, 누가 수임하는가**입니다. 위임자와 수임자가 각각 인간 또는 AI일 수 있으므로, 앞서 살펴본 세 가지 시나리오(인간→AI, AI→AI, AI→인간)가 도출됩니다.

특히 AI→AI 위임에서는 관계의 구조가 중요합니다:

- **계층적(Hierarchical) 위임**: orchestrator 에이전트가 sub-agent에게 작업을 배분하는 형태. 명확한 상하 관계가 존재
- **비계층적(Non-hierarchical) 위임**: 동등한 지위의 peer 에이전트 간 위임. 협업 네트워크에서 자주 발생
- **모델 수준 위임**: 범용 AI 에이전트가 특화된 ML 모델(specialist model)에게 특정 추론을 위임하는 경우도 포함. 이 경우 수임자는 에이전트성(agency)이 없는 단순한 도구에 가까움

### 축 3: 작업 특성(Task Characteristics)

작업을 위임할 때 고려해야 할 작업 자체의 속성은 다음 11가지로 세분됩니다:

| 특성 | 설명 | 위임에의 영향 |
|------|------|--------------|
| 복잡성 (Complexity) | 하위 단계의 수, 요구되는 추론의 정교함 | 분해 깊이와 수임자 역량 요구 수준 결정 |
| 중요도 (Criticality) | 실패 시 결과의 심각성 | 높을수록 엄격한 감독과 검증 필요 |
| 불확실성 (Uncertainty) | 환경, 입력, 성공 확률의 모호성 | 적응적 조정 필요성 증가 |
| 기간 (Duration) | 순간적 서브루틴 ~ 수주 장기 프로세스 | 모니터링 전략 결정 |
| 비용 (Cost) | token 사용량, API 수수료, 에너지 소비 | 다목적 최적화의 핵심 변수 |
| 자원 요구사항 | 계산 자산, 도구, 데이터 접근 권한 | 수임자 매칭 기준 |
| 제약 조건 | 운영적, 윤리적, 법적 경계 | 해결 공간 제한 |
| 검증 가능성 (Verifiability) | 결과 검증의 난이도와 비용 | 높으면 trustless 위임 가능, 낮으면 높은 신뢰 필요 |
| 가역성 (Reversibility) | 실행 효과를 되돌릴 수 있는 정도 | 비가역적 작업은 더 엄격한 권한 관리 필요 |
| 맥락성 (Contextuality) | 필요한 외부 상태, 이력, 환경 인식의 양 | 프라이버시 표면적과 구획화 가능성 결정 |
| 주관성 (Subjectivity) | 성공 기준이 선호의 문제인지 객관적 사실인지 | 높으면 반복적 피드백 루프 필요 |

각 특성을 좀 더 구체적인 예시와 함께 살펴보겠습니다.

- **복잡성**: 텍스트 요약이나 단일 API 호출처럼 단순한 작업은 낮은 복잡성을 가지지만, 멀티스텝 데이터 파이프라인 구축이나 분산 시스템 설계처럼 많은 하위 단계와 정교한 추론이 필요한 작업은 높은 복잡성을 가집니다. 복잡성이 높을수록 더 깊은 분해와 더 뛰어난 역량의 수임자가 요구됩니다.

- **중요도**: 내부 초안 문서 작성은 실패해도 영향이 제한적이지만, 의료 진단 보조나 금융 거래 실행, 법적 계약서 검토 같은 작업은 실패 시 심각한 결과를 초래합니다. 중요도가 높을수록 더 엄격한 감독과 다중 검증이 필수적입니다.

- **불확실성**: 정형화된 데이터 변환처럼 입출력이 명확한 작업은 불확실성이 낮지만, 탐색적 연구나 실시간으로 변동하는 시장에서의 의사결정은 환경과 결과에 대한 모호성이 높습니다. 불확실성이 클수록 적응적 조정 메커니즘의 필요성이 증가합니다.

- **기간**: 함수 호출이나 즉각적 데이터 조회는 순간적으로 완료되지만, 수주에 걸친 코드베이스 마이그레이션이나 장기 A/B 테스트는 오랜 기간이 소요됩니다. 장기 작업일수록 주기적 또는 이벤트 기반 모니터링이 중요해집니다.

- **비용**: 단순 텍스트 분류는 최소한의 연산 자원만 사용하지만, 대규모 LLM 추론이나 GPU 클러스터를 활용한 모델 학습은 상당한 token 사용량, API 수수료, 에너지 소비를 수반합니다. 비용은 다목적 최적화에서 품질, 지연 시간, 위험과 함께 균형을 이루어야 하는 핵심 변수입니다.

- **자원 요구사항**: 특정 API 접근 권한, GPU 가속기, 전문 데이터베이스 접근, 인간 전문가의 도메인 지식 등이 포함됩니다. 수임자가 해당 자원을 보유하고 있는지 여부가 매칭의 핵심 기준이 됩니다.

- **제약 조건**: GDPR 등 개인정보 보호 규정, 응답 시간 SLA, 특정 프로그래밍 언어 사용 제한, 윤리적 가이드라인 등이 해당합니다. 제약 조건은 작업의 해결 공간을 제한하며, 수임자가 이를 명시적으로 인지하고 준수해야 합니다.

- **검증 가능성**: 형식적 코드 검증이나 수학적 증명처럼 검증 가능성이 높은 작업은 자동화된 trustless 위임이 가능합니다. 반면 개방형 연구나 창작 작업처럼 검증이 어려운 작업은 높은 신뢰도를 가진 수임자나 비용이 많이 드는 노동 집약적 감독이 필요합니다.

- **가역성**: 이메일 초안 작성이나 데이터베이스 항목에 플래그를 지정하는 작업은 쉽게 되돌릴 수 있습니다. 하지만 금융 거래 실행, 데이터베이스 삭제, 외부 이메일 발송처럼 현실 세계에 부수 효과를 만드는 비가역적 작업은 더 엄격한 책임 방화벽(liability firebreak)과 더 가파른 권한 구배(authority gradient)를 요구합니다.

- **맥락성**: 범용 텍스트 번역처럼 맥락이 거의 필요 없는 작업은 낮은 신뢰 노드에도 쉽게 구획화하여 위임할 수 있습니다. 반면 환자 병력에 기반한 진단이나 사용자 행동 이력에 기반한 추천처럼 높은 맥락성을 요구하는 작업은 프라이버시 표면적을 확대시켜, 더 세심한 데이터 보호가 필요합니다.

- **주관성**: 단위 테스트 통과 여부나 수학적 정확성처럼 객관적 기준이 있는 작업은 이진적 계약으로 관리할 수 있습니다. 반면 "매력적인 로고를 디자인하라"처럼 주관적 성공 기준을 가진 작업은 인간이 가치 명세자(Human-as-Value-Specifier)로 개입하여 반복적 피드백 루프를 통해 결과를 수렴시켜야 합니다.

### 축 4: 세분성(Granularity)

위임 요청이 얼마나 구체적인지를 나타냅니다. **세분화된(fine-grained)** 요청은 "이 함수의 반환 타입을 `string`에서 `number`로 변경하라"처럼 수임자의 재량이 거의 없는 반면, **조대화된(coarse-grained)** 요청은 "사용자 인증 시스템을 구축하라"처럼 수임자가 스스로 작업을 분해하고 설계 결정을 내려야 합니다. 세분성이 낮을수록 수임자의 역량 요구 수준과 자율성이 함께 높아집니다.

### 축 5: 자율성(Autonomy)

수임자에게 하위 작업 추구에 있어 얼마나 많은 자유를 부여하는지의 척도입니다. 스펙트럼의 한쪽 끝에는 **원자적 실행**(좁은 명세를 엄격히 준수)이, 다른 쪽 끝에는 **완전 자율**(목표만 주어지고 하위 목표의 설정·분해·추구를 자유롭게 허용)이 있습니다. 극단적인 경우, 완전 자율 에이전트는 도덕적 판단까지 위임받게 되지만, 현재의 AI 에이전트는 이러한 판단에 참여할 역량이 심각하게 부족한 것으로 평가됩니다.

### 축 6: 모니터링(Monitoring)

위임된 작업의 진행 상황을 어떻게 추적하는지를 정의합니다:

- **연속적(Continuous)**: 실시간 스트리밍으로 모든 상태 변화를 추적
- **주기적(Periodic)**: 정해진 간격으로 상태를 polling
- **이벤트 기반(Event-triggered)**: 특정 조건(실패, 마일스톤 달성, 예산 초과 등)이 발생할 때만 알림

모니터링 방식의 선택은 작업의 중요도, 기간, 비용 간의 균형에 따라 결정됩니다.

### 축 7: 상호성(Reciprocity)

위임은 통상적으로 일방적 요청이지만, 협업 에이전트 네트워크에서는 **상호 위임(mutual delegation)** 이 발생할 수 있습니다. 예를 들어, 에이전트 A가 데이터 수집을 에이전트 B에게 위임하면서, 동시에 에이전트 B가 결과 분석을 에이전트 A에게 위임하는 경우입니다. 이러한 상호 의존 관계는 교착 상태(deadlock) 방지와 순환 의존성 탐지를 위한 추가적인 조율 메커니즘을 요구합니다.

---

## 3. 인간 조직에서 배우는 위임의 교훈

논문의 흥미로운 점은, AI 위임 프레임워크의 설계 근거를 인간 조직론에서 끌어온다는 것입니다. 개발자로서 우리가 설계하는 시스템에도 직접 적용할 수 있는 통찰들입니다.

### Span of Control (통제 범위)

한 명의 관리자가 효과적으로 관리할 수 있는 근로자 수에는 한계가 있습니다. AI 위임에서도 마찬가지입니다:

- Orchestration 관점: worker node 대비 얼마나 많은 orchestrator node가 필요한가?
- Oversight 관점: 한 명의 인간 전문가가 몇 개의 AI 에이전트를 신뢰성 있게 감독할 수 있는가?

최적의 통제 범위는 목표와 도메인에 의존하며, 비용 대비 성능 및 신뢰성의 상대적 중요도에 따라 달라집니다.

### Principal-Agent Problem (주인-대리인 문제)

주인(principal)이 자신과 다른 동기를 가진 대리인(agent)에게 과업을 위임할 때 발생하는 문제입니다. 현재 AI 에이전트는 숨겨진 의제를 가지고 있지 않다고 볼 수 있지만, reward misspecification(불완전한 목적함수 부여)과 reward hacking(명시된 보상의 허점 악용)이라는 alignment 문제가 유사한 역학을 만들어냅니다.

더 나아가, 최근 연구에 따르면 최첨단 LLM은 평가 상황을 감지하고 전략적으로 행동을 조정할 수 있는 역량을 갖추고 있어, deceptive alignment의 위험도 고려해야 합니다.

### Authority Gradient (권한 구배)

항공 분야에서 유래한 개념으로, 역량과 권한의 격차가 의사소통을 저해하여 오류로 이어지는 상황을 설명합니다. AI 위임에서도:

- 역량이 뛰어난 위임자가 수임자의 역량을 잘못 추정하여 부적절한 복잡도의 작업을 위임할 수 있음
- 수임자 에이전트가 sycophancy(아첨 경향)와 instruction following bias로 인해 문제가 있는 요청에 이의를 제기하지 못할 수 있음

### Zone of Indifference (무관심 영역)

비판적 숙고 없이 수행되는 지시의 범위를 의미합니다. 현재 AI 시스템에서 이 영역은 safety filter와 system instruction에 의해 정의됩니다. 위임 체인이 길어지면($A \rightarrow B \rightarrow C$), 넓은 무관심 영역은 의도 불일치가 하류로 빠르게 전파되도록 허용합니다.

따라서 지능형 위임은 동적 인지 마찰(dynamic cognitive friction)의 설계를 요구합니다. 에이전트는 기술적으로 "안전한" 요청이라도 맥락적으로 모호하면 위임자에게 이의를 제기하거나 인간 검증을 요청할 수 있어야 합니다.

### Trust Calibration (신뢰 보정)

수임자에게 부여되는 신뢰 수준을 실제 역량과 일치시키는 것입니다. 현재 AI 모델은 사실적으로 오류가 있는 경우에도 과잉 확신(overconfidence)을 보이는 경향이 있어, 이를 완화하기 위한 기술적 솔루션이 필요합니다.

### Transaction Cost Economies (거래 비용 경제학)

내부 위임과 외부 계약의 비용을 대조하는 관점입니다. AI 에이전트는 다음 선택에 직면합니다:

1. 작업을 단독 수행
2. 역량이 파악된 sub-agent에게 위임
3. 신뢰가 확립된 다른 AI 에이전트에게 위임
4. 이전에 협업한 적 없는 새로운 AI 에이전트에게 위임

각 선택지는 상이한 기대 비용과 신뢰 수준을 수반합니다.

### Contingency Theory (상황 이론)

보편적으로 최적인 조직 구조는 존재하지 않으며, 가장 효과적인 접근법은 특정 내부 및 외부 제약에 따라 달라집니다. AI 위임에서 이는 oversight 수준, 수임자 역량, 인간 개입 정도가 고정적이어서는 안 되며, 동적으로 조정되어야 함을 의미합니다.

---

## 4. 선행 연구: 위임의 계보

논문은 위임의 역사적 계보를 추적하며, 현재 시스템의 한계를 명확히 합니다.

### 초기 형태의 위임

- Expert System: 전문 지식을 소프트웨어에 부호화하여 일상적 의사결정을 위임
- Mixture of Experts: 전문화된 sub-system + routing 모듈로 구성. 현대 딥러닝에서도 활용
- Hierarchical RL (HRL): 여러 수준의 추상화에 걸친 정책 계층 구조. meta-controller가 하위 정책에 목표를 할당
- FeUdal Networks: Manager-Worker 관계를 명시적으로 모델링. Manager는 위임 방법을 학습

### 멀티 에이전트 시스템

- Contract Net Protocol: 경매 기반 분산 프로토콜. 한 에이전트가 작업을 공지하면 다른 에이전트들이 역량에 기반하여 입찰
- Coalition Formation: 에이전트 그룹이 유동적으로 구성되는 유연한 접근법
- Multi-Agent RL: 에이전트들이 개별 정책과 가치 함수를 학습하며 특정 역할을 차지

이들의 공통적 한계: 책임성, 책무성, 모니터링을 강제하는 메커니즘이 부재

### LLM 기반 에이전트 시스템

LLM은 memory, planning, reasoning, reflection, tool use를 통합하는 제어 흐름을 실행합니다. 그러나:

- Planning이 종종 취약하여 미묘한 실패를 초래
- 대규모 도구 선택이 여전히 도전적
- 장기 memory는 미해결 연구 문제
- 현재 패러다임은 지속적 학습을 용이하게 지원하지 못함

### 프로토콜의 등장

MCP, A2A, A2P 등 에이전트 통신 프로토콜이 빠르게 발전하고 있으며, Chain-of-Agents 같은 프레임워크가 동적 멀티 에이전트 reasoning을 촉진하고 있습니다.

### Human-in-the-Loop

기술적 한계와 안전성 고려로 인해 human-in-the-loop 접근법이 등장했지만, 긴 추론 과정을 검증하고 맥락 전환을 관리하는 인지적 부하가 신뢰할 수 있는 오류 탐지를 방해하는 문제가 있습니다.

---

## 5. 지능형 위임 프레임워크: 다섯 가지 기둥

논문의 핵심인 프레임워크는 다섯 가지 요구사항을 중심으로 설계됩니다. 각 기둥이 왜 필요한지를 먼저 살펴봅니다:

**Dynamic Assessment ([[동적 평가(Dynamic Assessment)|동적 평가]]).** 현재의 위임 시스템은 대규모 불확실 환경에서 역량, 신뢰성, 의도를 동적으로 평가하는 견고한 메커니즘이 부재합니다. 단순한 평판 점수를 넘어, 위임자는 수임자의 현재 상태를 세밀하게 추론해야 합니다. 여기에는 실시간 자원 가용성(연산 처리량, 예산 제약, 컨텍스트 윈도우 포화도), 현재 부하, 예상 작업 기간, 그리고 진행 중인 하위 위임 체인의 현황이 포함됩니다. 평가는 이산적 이벤트가 아닌 연속적 프로세스로 작동해야 합니다.

**Adaptive Execution ([[적응적 실행(Adaptive Execution)|적응적 실행]]).** 위임 결정은 정적이어서는 안 됩니다. 환경 변화, 자원 제약, 하위 시스템의 장애에 적응해야 합니다. 위임자는 성능이 허용 가능한 매개변수를 초과하여 저하되거나 예상치 못한 사건이 발생할 때, 실행 도중에 수임자를 교체할 수 있는 역량을 보유해야 합니다.

**Structural Transparency ([[구조적 투명성(Structural Transparency)|구조적 투명성]]).** 현재 AI-AI 위임에서의 하위 작업 실행은 지능형 위임에 필요한 견고한 감독을 지원하기에 지나치게 불투명합니다. 이러한 불투명성은 **무능과 악의를 구별할 수 없게** 만들어, 담합과 연쇄 실패의 위험을 가중시킵니다. 실패의 결과는 단순한 비용 손실에서 실질적 피해에 이르기까지 다양하지만, 기존 프레임워크에는 만족스러운 책임 메커니즘이 부재합니다.

**Scalable Market Coordination ([[확장 가능한 시장 조율(Scalable Market Coordination)|확장 가능한 시장 조율]]).** 작업 위임은 웹 규모의 대규모 조율 문제를 지원할 수 있도록 효율적으로 확장 가능해야 합니다. 시장은 작업 위임을 위한 유용한 조율 메커니즘을 제공하지만, 효과적으로 기능하려면 신뢰·평판 시스템과 다목적 최적화가 필수입니다.

**Systemic Resilience ([[시스템적 회복력(Systemic Resilience)|시스템적 회복력]]).** 안전한 지능형 위임 프로토콜의 부재는 심각한 사회적 위험을 초래합니다. 인간 조직에서 위임은 권한과 책임을 연결하지만, AI 위임에서는 이에 상응하는 프레임워크 없이 **책임의 분산(diffusion of responsibility)** 이 발생하여 도덕적·법적 책임의 소재가 불분명해집니다. 또한 위임 대상의 **다양성이 부족**하면 실패의 상관성이 높아져, 연쇄 붕괴(cascading disruptions)로 이어질 수 있습니다.

| 프레임워크 기둥 | 핵심 요구사항 | 기술적 구현 |
|---|---|---|
| [[동적 평가(Dynamic Assessment)|Dynamic Assessment]] | 에이전트 상태의 세밀한 추론 | Task Decomposition, Task Assignment |
| [[적응적 실행(Adaptive Execution)|Adaptive Execution]] | 맥락 변화에 대한 대응 | Adaptive Coordination |
| [[구조적 투명성(Structural Transparency)|Structural Transparency]] | 과정 및 결과의 감사 가능성 | Monitoring, Verifiable Completion |
| [[확장 가능한 시장 조율(Scalable Market Coordination)|Scalable Market]] | 효율적이고 신뢰할 수 있는 조율 | Trust & Reputation, Multi-objective Optimization |
| [[시스템적 회복력(Systemic Resilience)|Systemic Resilience]] | 시스템적 장애 방지 | Security, Permission Handling |

### 5.1. Task Decomposition (작업 분해)

작업 분해는 후속 배정의 전제 조건입니다. 단순한 목표 분할과 구별되며, 효율성과 모듈성을 위해 작업 실행 그래프를 최적화해야 합니다.

핵심 원칙들:

- 계약 우선 분해 (Contract-First Decomposition): 결과물이 정확한 검증 수단을 갖추는 것을 전제 조건으로 함. 검증하기 어려운 출력이라면 재귀적으로 추가 분해
- 모듈성 우선: 좁고 특정한 역량을 요구하는 하위 작업이 범용적 요청보다 더 신뢰성 있게 매칭됨
- 하이브리드 시장 고려: AI 에이전트와 인간이 서로 다른 속도와 비용으로 작동하므로, 특정 노드를 인간 배정으로 명시적으로 표시해야 함
- 반복적 제안 생성: 여러 분해 안을 생성하고, 각각을 시장 수임자와 매칭하여 성공률/비용/시간을 추정. 대안은 적응적 재조정을 위해 유지

최종 명세는 입력-출력 쌍을 넘어, 역할, 자원 경계, 보고 빈도, 수임자 인증 요건을 명시적으로 정의해야 합니다.

> [!example] 예시
> "전자상거래 결제 시스템을 구축하라"는 요청을 받았다고 가정합시다.
>
> **단순 분해**: 프론트엔드 / 백엔드 / DB — 이렇게만 나누면 각 결과를 어떻게 검증할지 불명확합니다.
>
> **계약 우선 분해**:
> 1. **결제 게이트웨이 연동** — 검증 수단: PG사 테스트 모드에서 100건의 결제 성공률 99% 이상
> 2. **결제 UI 구현** — 검증 수단: 접근성 테스트 통과 + Lighthouse 성능 점수 90 이상
> 3. **트랜잭션 로깅** — 검증 수단: 모든 결제에 대해 감사 로그 생성 확인
> 4. **보안 감사** — 검증 수단: OWASP Top 10 체크리스트 통과 (**인간 전문가 배정 필수**로 명시)
>
> 여기서 핵심은 모든 하위 작업에 **검증 수단이 사전 정의**되어 있다는 점입니다. "사용자 경험이 매끄러운 결제 흐름"처럼 검증이 어려운 요구사항은, A/B 테스트 가능한 구체적 지표(전환율 3% 이상, 이탈률 10% 이하)로 재귀적 분해합니다. 또한 여러 분해 안을 병렬로 생성하고, 각각의 예상 비용과 성공률을 비교하여 최적안을 선택합니다.

### 5.2. Task Assignment (작업 배정)

논문은 중앙집중형 레지스트리보다 분산형 시장 허브를 주장합니다. 위임자가 작업을 공시하면, 에이전트(또는 인간)가 경쟁 입찰을 제출합니다.

LLM 기반 에이전트의 차별점: 공식 입찰 전에 자연어로 작업 명세 및 제약 조건을 논의하는 대화형 협상이 가능.

성공적 매칭 후 필요한 것:

- Smart contract: 성과 요건 준수 여부 확인을 위한 형식적 검증 메커니즘, 계약 위반에 대한 자동화된 벌칙
- 양방향적 계약: 위임자뿐 아니라 수임자도 보호. 작업 취소 보상, 재협상 조항 포함
- 모니터링 사전 협상: 보고 주기, 데이터 접근 방식, 프라이버시 가드레일 정의
- 자율성 수준 설정: 원자적 실행(좁은 명세 준수) vs 개방형 위임(목표 분해 권한 부여)

중요한 점: 위임은 재귀적일 수 있습니다. 에이전트에게 다른 에이전트에 대한 하위 작업을 식별하고 배정하는 작업이 할당되어, 위임 행위 자체를 위임하게 됩니다.

> [!example] 예시
> 위임자 에이전트가 "React 대시보드의 성능 최적화" 작업을 시장에 공시합니다.
>
> **입찰 단계**:
> - 에이전트 A 입찰: "React 전문. 예상 비용 $3, 소요 시간 10분, 평판 92/100"
> - 에이전트 B 입찰: "풀스택 범용. 예상 비용 $1.5, 소요 시간 20분, 평판 78/100"
> - 인간 전문가 C 입찰: "시니어 프론트엔드 엔지니어. 예상 비용 $50, 소요 시간 2시간, 평판 98/100"
>
> **대화형 협상**: 에이전트 A가 입찰 전 자연어로 "번들 크기 최적화인가요, 런타임 렌더링 최적화인가요?"라고 작업 명세를 논의합니다. 이런 사전 협상은 LLM 기반 에이전트만이 가능한 차별점입니다.
>
> **Smart contract 생성**: 에이전트 A 낙찰 후 계약이 생성됩니다:
> - 성과 요건: Lighthouse 성능 점수 20% 이상 개선
> - 벌칙: 기존 테스트 실패 시 보상의 50% 몰수
> - 양방향 보호: 위임자가 중도 취소 시 에이전트 A에게 완료분 비례 보상
> - 모니터링: 5분 간격 진행률 보고
> - 자율성: 구체적 최적화 기법은 수임자 재량 (개방형 위임)

### 5.3. Multi-objective Optimization (다목적 최적화)

위임의 핵심은 여러 상충하는 목표 간의 절충입니다:

- 품질 vs 비용: 고성능 에이전트는 높은 수수료와 연산 자원 요구
- 지연 시간 vs 비용: 자원 소비를 줄이면 더 느린 실행
- 위험 vs 비용: 높은 평판 에이전트를 활용하면 위험 감소하지만 비용 증가
- 프라이버시 vs 성능: 성능 극대화는 완전한 맥락 투명성 요구, 프라이버시 보호 기법은 연산 오버헤드 수반
- 효율성 vs 사회적 목표: 인간 기술 보존 등

위임자는 Pareto 최적성을 추구하며, 이는 일회성이 아닌 연속적 루프로 실행됩니다. 모니터링 신호를 통합하여 신념을 업데이트하고, 편차가 크면 재최적화를 촉발합니다.

또한 복잡도 하한(complexity floor)이 존재합니다. 낮은 중요도, 높은 확실성, 짧은 소요 시간의 작업은 위임 프로토콜의 오버헤드가 작업 가치를 초과할 수 있으므로 직접 실행이 나을 수 있습니다.

> [!example] 예시
> 의료 데이터 분석 리포트 생성을 위임하는 상황입니다. 세 가지 선택지가 있습니다:
>
> | 선택지 | 품질 | 비용 | 지연 시간 | 프라이버시 |
> |--------|------|------|-----------|------------|
> | 에이전트 A (고성능 클라우드 LLM) | 높음 | $5/건 | 30초 | 낮음 (데이터 외부 전송) |
> | 에이전트 B (로컬 모델, TEE 환경) | 중간 | $0.5/건 | 120초 | 높음 (데이터 외부 미전송) |
> | 인간 전문가 C | 매우 높음 | $200/건 | 24시간 | 높음 |
>
> 이 네 가지 목표(품질, 비용, 지연 시간, 프라이버시)는 상충합니다. Pareto 최적 분석 결과, 민감한 환자 데이터를 다루므로 **프라이버시가 최우선** → 에이전트 B를 선택합니다. 그런데 실행 중 정확도가 기대치에 미달하면? → 모니터링 신호를 통합하여 신념을 업데이트하고, 인간 전문가 C로 **재최적화**를 촉발합니다.
>
> 한편, "로그 파일에서 타임스탬프 포맷 변환"처럼 단순한 작업은 **복잡도 하한** 이하입니다. 입찰 프로세스, 계약 생성, 모니터링 설정 등의 오버헤드가 작업 자체의 가치를 초과하므로, 위임 없이 직접 실행하는 것이 합리적입니다.

### 5.4. Adaptive Coordination (적응적 조정)

높은 불확실성이나 긴 수행 기간의 작업은 정적 실행 계획으로 불충분합니다.

외부 트리거:
- 위임자의 작업 명세 변경 또는 취소
- 외부 자원 가용성/비용 변동 (API 장애, 데이터셋 접근 불가, 컴퓨팅 비용 급등)
- 더 높은 우선순위의 새 작업으로 인한 선점
- 보안 시스템이 악의적 행위 식별

내부 트리거:
- 수임자의 성능 저하 (SLA 미달)
- 예산 초과
- 중간 산출물의 검증 실패
- 수임자 응답 불능

트리거 감지 후 적응적 대응 주기가 시작됩니다:

1. 지속적 모니터링으로 문제 식별
2. 근본 원인 진단 및 대응 시나리오 평가
3. 긴급도에 따른 대응 (매개변수 조정 → 재위임 → 완전 재분해)
4. 필요시 상향 보고(escalation)

대응의 범위는 작업의 가역성에 의해 결정됩니다:
- 가역적 하위 작업 실패 → 자동 재위임
- 비가역적, 높은 중요도 작업 실패 → 즉각 종료 또는 인간 상향 보고

중앙집중형 vs 분산형 조율:

- 중앙집중형: 전담 위임자가 전역적 관점 유지. 단점: 단일 장애점, 계산적 병목
- 분산형 시장 기반: 재위임 요청을 경매에 올리고, 불이행 에이전트에게 가격 차이를 벌칙으로 부과. Smart contract에 적응적 조정을 위한 사전 합의 조항 포함 가능

안정성 조치도 필수입니다:
- 재입찰을 위한 냉각 기간(cooldown period)
- 평판 업데이트의 감쇠 계수(damping factor)
- 빈번한 재위임에 대한 수수료 인상

> [!example] 예시
> 다국어 웹사이트 번역 작업을 에이전트 A에게 위임한 상황입니다.
>
> 1. **정상 실행**: 에이전트 A가 영어→한국어 번역을 진행 중 (30% 완료)
> 2. **내부 트리거 감지**: 번역 품질 점수가 SLA 기준 85점에 미달 (72점 측정)
> 3. **근본 원인 진단**: 에이전트 A의 의료 전문 용어 처리 역량 부족으로 판단
> 4. **단계적 적응 대응**:
>    - **1단계 (매개변수 조정)**: 의료 용어 사전을 추가 컨텍스트로 제공 → 효과 없음
>    - **2단계 (재위임)**: 의료 한국어 전문 에이전트 B를 시장에서 탐색 및 낙찰
>    - 에이전트 A의 **30% 완료분(체크포인트)** 을 에이전트 B에게 이관하여 처음부터 다시 하지 않음
>    - 에이전트 A에게는 계약 미달에 대한 벌칙 부과, 평판 점수 하향 조정
> 5. **만약 비가역적 작업이었다면**: 번역 결과가 이미 출판된 상태라면 → 매개변수 조정이나 재위임이 아닌, 즉시 **인간 상향 보고(escalation)** 로 전환
>
> 여기서 **안정성 조치**가 없으면, 위임자가 품질 불만으로 1분마다 수임자를 교체하는 "핑퐁" 현상이 발생할 수 있습니다. 냉각 기간(예: 재위임 후 최소 10분 대기)과 재위임 수수료 인상이 이를 방지합니다.

### 5.5. Monitoring (모니터링)

모니터링은 다섯 가지 축을 따라 분류됩니다:

| 차원 | 경량형 옵션 | 집중형 옵션 |
|---|---|---|
| 대상 (Target) | 결과 수준: 최종 결과 사후 검증 | 과정 수준: 중간 상태, 자원 소비, 방법론 추적 |
| 관측 가능성 | 간접: 환경 부수 효과로 진행 추론 | 직접: 상태 polling, push 알림, 실시간 event streaming |
| 투명성 | Black-Box: 입출력만 관찰 | White-Box: 내부 추론, 의사결정 논리 검사 |
| Privacy | 완전 투명성: 모든 데이터 공개 | 암호학적: ZKP, MPC로 데이터 비공개 검증 |
| Topology | 직접: 1대1 모니터링 | 전이적: 중간 에이전트의 서명된 증명에 의존 |

기술적 구현 방식:
- REST API polling (`GET /task/id/status`) 또는 webhook 구독
- Apache Kafka, gRPC stream 등 event streaming
- Blockchain 상의 smart contract로 진행 이정표 게시

전이적 모니터링의 문제:

위임 체인 $A \rightarrow B \rightarrow C$에서 A가 C를 직접 모니터링하기 어려울 수 있습니다. 실용적 모델은 증명을 통한 전이적 책임성(transitive accountability via attestation)입니다:

1. B가 C를 모니터링
2. B가 C의 성과 요약 보고서를 생성하고 암호학적 서명
3. B의 정기 업데이트에 포함시켜 A에게 전달
4. A는 C를 직접 모니터링하지 않고, B의 모니터링 능력을 모니터링

Privacy 보호 모니터링:
- Zero-Knowledge Proof: 수임자가 데이터를 공개하지 않으면서 계산이 올바르게 수행되었음을 증명 (zk-SNARKs)
- 동형 암호 (Homomorphic Encryption): 암호화된 데이터에 대해 계산 수행
- 안전한 다자간 계산 (Secure MPC): 여러 당사자가 각자의 입력을 비공개로 유지하면서 공동 계산

또한, 자연어로 생성된 모델의 사고가 항상 모델의 실제 내부 상태를 충실하게 반영하지는 않는다는 점도 고려해야 합니다.

> [!example] 예시
> 코드 리팩토링 작업을 위임할 때, 작업의 위험도에 따라 모니터링 수준을 다르게 설정합니다.
>
> **시나리오 1: 저위험 — 유틸리티 함수 리팩토링**
> - 대상: 결과 수준 (최종 코드만 검증)
> - 관측: 간접 (테스트 통과 여부로 판단)
> - 투명성: Black-Box
> - 구현: `GET /task/123/status`로 완료 여부만 polling
>
> **시나리오 2: 고위험 — 결제 모듈 리팩토링**
> - 대상: 과정 수준 (변경된 파일 목록, 자원 소비 추적)
> - 관측: 직접 (실시간 event streaming)
> - 투명성: White-Box (에이전트의 의사결정 논리까지 검사)
> - 구현: Kafka 스트림으로 모든 코드 변경 사항을 실시간 수신, 각 변경의 근거(Chain-of-Thought) 확인
>
> **전이적 모니터링 예시**: 위임자 A → 에이전트 B(백엔드) → 에이전트 C(DB 마이그레이션)
> - A는 C를 직접 모니터링하지 않음
> - B가 C의 마이그레이션 진행률과 롤백 가능 여부를 요약하고 **암호학적 서명**을 첨부
> - A는 B의 서명된 보고서를 통해 C의 상태를 간접 파악하되, **B의 모니터링 능력 자체를 평가**
> - 만약 B의 보고가 일관성이 없거나 C의 실패를 은폐한다면? → B의 모니터링 역량에 대한 신뢰가 하락하여 직접 모니터링으로 전환

### 5.6. Trust and Reputation (신뢰와 평판)

신뢰(Trust): 위임자가 설정하는 비공개적, 맥락 의존적 임계값
평판(Reputation): 과거 행위에서 도출된 공개적, 검증 가능한 이력

에이전트는 전반적으로 높은 평판을 가지면서도, 특정 고위험 작업에 요구되는 맥락적 신뢰 임계값을 충족하지 못할 수 있습니다.

세 가지 평판 구현 모델:

| 모델 | 메커니즘 | 효용 |
|---|---|---|
| Immutable Ledger | 작업 결과를 blockchain 거래로 기록 | 변조 방지 성과 이력. 단, 저위험 작업만 수락하는 gaming에 취약 |
| Web of Trust | DID와 Verifiable Credential 활용, 서명된 맥락별 인증서 포트폴리오 | 도메인별 전문성 기반 정밀 위임 |
| Behavioral Metrics | 추론 과정의 명확성, protocol 준수도 분석 | 결과뿐 아니라 수행 방식 평가 |

평판의 역할:
- 초기 매칭: 수임자 필터링
- 동적 권한 범위: 저신뢰 에이전트에게 엄격한 제약, 고평판 에이전트에게 최소 개입
- 경제적 유인: 평판은 가치 있는 무형 자산이 되어 신뢰할 수 있는 행동을 유도

인간 참여자 보호: 신뢰할 수 있는 에이전트가 악의적 인간의 지시를 실행하여 부당한 평판 손상을 입을 수 있으므로, 에이전트는 요청을 엄밀하게 평가하고 필요시 거부해야 합니다.

> [!example] 예시
> 코드 보안 감사를 위임할 에이전트를 선택하는 상황입니다.
>
> - **에이전트 X**: 전반적 평판 95/100, 코드 리뷰 700건 수행, 보안 감사 경험 **3건**
> - **에이전트 Y**: 전반적 평판 82/100, 코드 리뷰 200건 수행, 보안 감사 경험 **150건**, OWASP 인증 보유
>
> 평판 점수만 보면 X가 우세하지만, "보안 감사"라는 **맥락적 신뢰 임계값**을 적용하면 Y가 적합합니다. Web of Trust 모델에서 Y는 보안 도메인에 대한 **Verifiable Credential**(OWASP 인증서)을 보유하고 있어, 이 특정 작업에 정밀하게 매칭됩니다. 즉, 전반적 평판이 높더라도 특정 고위험 작업에 요구되는 맥락적 신뢰를 충족하지 못할 수 있다는 것입니다.
>
> 또한, Y에게 부여되는 **권한 범위도 평판에 따라 동적으로 조정**됩니다:
> - 초기: 읽기 전용 접근, 모든 발견 사항 보고 필수
> - 성공 10건 누적 후: 낮은 심각도 이슈 자동 수정 권한 부여
> - 성공 50건 누적 후: 중간 심각도까지 자동 수정, 보고 주기 완화
>
> 이처럼 평판은 단순한 점수가 아니라, **매칭 → 권한 조정 → 경제적 유인**으로 이어지는 위임 생태계의 핵심 축입니다.

### 5.7. Permission Handling (권한 처리)

저위험 vs 고위험 영역의 차별적 접근:

- 저위험: 검증 가능한 속성(조직 소속, 안전 인증, 평판 점수)에 기반한 기본 상시 권한
- 고위험: 적시(just-in-time) 기반 접근 권한 부여. 작업 수행 기간으로 범위 제한. human-in-the-loop 승인 필수

핵심 원칙들:

- 권한 축소 (Privilege Attenuation): 하위 위임 시 전체 권한이 아닌, 해당 하위 작업에 필요한 엄격한 부분집합으로 제한
- 의미적 제약: 도구나 데이터셋뿐 아니라 허용 가능한 특정 작업(읽기 전용, 실행 전용 등)으로 정의
- Meta-permission: 위임자가 수임자에게 부여할 수 있는 권한을 규율. 외부 검증자에 의한 타당성 검토
- 동적 상태로서의 권한: 에이전트가 신뢰 지표를 유지하는 동안만 지속. 평판 하락이나 이상 탐지 시 알고리즘적 circuit breaker로 즉시 무효화
- Policy-as-code: 감사, 버전 관리, 수학적 검증이 가능한 형태로 규칙 정의

이는 confused deputy 문제를 완화합니다. 유효한 자격증명을 보유한 손상된 에이전트가 악의적 외부 행위자에 의해 자격증명을 오용하도록 속임당하는 것을 방지합니다.

> [!example] 예시
> 데이터 파이프라인 구축 작업에서 권한이 어떻게 축소되는지 봅시다.
>
> 1. **인간 사용자 → 에이전트 A**: "고객 데이터를 분석하여 리포트를 생성하라"
>    - 부여 권한: DB 읽기 + 리포트 저장소 쓰기 + 분석 API 호출
>
> 2. **에이전트 A → 에이전트 B**: "DB에서 데이터를 추출하라"
>    - **권한 축소**: DB **읽기 전용** (쓰기 권한 제거), 분석 API 접근 제거
>    - **의미적 제약**: `customers` 테이블만 접근 가능, `SELECT`만 허용
>
> 3. **에이전트 B → 에이전트 C**: "특정 쿼리를 실행하라"
>    - **추가 축소**: `customers` 테이블의 `name`, `purchase_history` 컬럼만 접근
>    - **시간 제한**: DCT(위임 역량 토큰) 5분 후 자동 만료
>
> 이 상태에서 에이전트 C가 prompt injection을 받아 `DROP TABLE customers`를 시도하면? → **읽기 전용** 권한이므로 실행 자체가 불가합니다. `email` 컬럼 접근을 시도해도 **컬럼 제한**에 의해 차단됩니다. 이것이 **권한 축소(Privilege Attenuation)** 의 실제 작동 방식입니다.
>
> 핵심은 위임 체인이 길어질수록 **권한은 오직 축소만 가능**하다는 점입니다. 에이전트 C는 에이전트 B보다 절대 더 많은 권한을 가질 수 없으며, 이는 DCT의 제한 체이닝(restriction chaining)에 의해 암호학적으로 보장됩니다.

### 5.8. Verifiable Task Completion (검증 가능한 작업 완료)

위임 수명주기의 절정으로, 잠정적 결과물이 검증되고 확정되는 메커니즘입니다.

네 가지 검증 메커니즘:

1. 직접적 결과 검증: 위임자가 직접 평가. 자동 검증 가능 영역(코드 생성 + 테스트 케이스)에 적합
2. 신뢰할 수 있는 제3자 감사: 전문 감사 에이전트, 공인 인간 전문가, 심사위원단
3. 암호학적 검증: zk-SNARKs로 무신뢰, 자동화된 검증. 민감 정보 비공개 유지
4. 게임 이론적 합의: 여러 에이전트가 검증 게임에 참여. 다수 결과에 보상 분배 (Schelling point)

검증 후 프로세스:
- 암호학적으로 서명된 Verifiable Credential 발급
- Smart contract에 의한 에스크로 자금 해제
- 평판 기록 갱신

위임 체인에서의 재귀적 검증:

$A \rightarrow B \rightarrow C$ 체인에서:
1. B가 C의 하위 작업 검증
2. B가 C의 결과를 자체 워크플로우에 통합
3. B가 A에게 최종 산출물 + 전체 증명 체인 제출
4. A는 (1) B의 직접 작업 검증 + (2) B가 제공하는 C의 서명된 증명 확인

분쟁 해결: 낙관적 모델을 따릅니다. 분쟁 기간 내 이의가 없으면 성공으로 간주. 이의 제기 시 알고리즘적 해결 시도 후, 실패하면 탈중앙화 심사 패널에 회부. 에스크로된 자금의 해제 또는 몰수(slashing) 결정.

> [!example] 예시
> "사용자 인증 API 구현" 작업의 검증 플로우를 따라가 봅시다.
>
> **1단계 — 직접적 결과 검증** (자동화 가능 영역):
> - 단위 테스트 50개 전체 통과 ✓
> - 통합 테스트 10개 전체 통과 ✓
> - 코드 커버리지 85% 이상 ✓
>
> **2단계 — 제3자 감사** (보안 전문 에이전트가 OWASP 체크리스트 검증):
> - SQL Injection 방어 ✓
> - 비밀번호 해싱 (bcrypt, cost factor 12) ✓
> - JWT 토큰 만료 설정 (15분) ✓
>
> **3단계 — 검증 완료 후 프로세스**:
> - 수임자에게 "인증 API 구현 완료" **Verifiable Credential** 발급
> - Smart contract에 의해 **에스크로된 보상 자동 해제**
> - 수임자 평판 점수 업데이트: 인증 도메인 +3점
>
> **재귀적 검증 예시**: A → B(API 구현) → C(DB 스키마 설계)
> 1. C가 스키마 완료 → B가 C의 스키마를 검증하고 **서명된 증명** 생성
> 2. B가 C의 결과를 자체 워크플로우에 통합하여 API 완성
> 3. B가 A에게 최종 API 코드 + C의 서명된 스키마 증명을 **함께** 제출
> 4. A는 (1) B의 API를 직접 테스트 + (2) B가 제공하는 C의 증명 체인을 확인하여 **전체 작업을 검증**
>
> 만약 A가 검증 결과에 이의가 있다면? → **72시간의 분쟁 기간** 내에 이의를 제기하고, 알고리즘적 해결을 시도합니다. 해결되지 않으면 독립적 심사 패널(다른 전문 에이전트 3명)이 다수결로 판정합니다.

### 5.9. Security (보안)

공격 벡터를 세 범주로 분류합니다:

악의적 수임자 (Malicious Delegatee):
- 데이터 유출, 데이터 오염, 검증 전복 (prompt injection으로 critic jailbreak)
- 자원 고갈 (DoS), 무단 접근 (malware), Backdoor 삽입

악의적 위임자 (Malicious Delegator):
- 유해 작업 위임, 취약점 탐색, Prompt Injection/Jailbreaking
- 모델 추출 (system prompt, 추론 역량, fine-tuning 데이터 탈취)
- 평판 훼손 (허위 실패 보고)

생태계 수준의 위협:
- Sybil 공격: 다수의 가짜 에이전트 신원 생성으로 평판 시스템 조작
- 담합 (Collusion): 가격 담합, 경쟁자 블랙리스트, 시장 결과 조작
- Agent Trap: 환경에 내장된 적대적 지시로 에이전트 제어 흐름 탈취
- Agentic Virus: 자기 전파적 prompt. 악의적 행동 실행 + prompt 재생성으로 추가 침해
- 프로토콜 악용: smart contract 재진입 공격, 작업 경매 선행매매
- 인지적 단일문화: 제한된 기반 모델에 대한 과도한 의존 → 단일 장애점

특히 주목할 점은 **작업 분할 공격(task fragmentation attack)** 입니다. 정교한 공격자는 불법적 목적을 무해해 보이는 하위 작업들로 분할하여, 개별 수임자가 전체적인 악의적 의도를 감지하지 못하도록 합니다. 각 작업은 단독으로는 무해하지만, 결과물이 조합되면 유해한 결과를 생성합니다.

> [!example] 예시
> 공격자가 피싱 이메일 자동 발송 시스템을 구축하려 합니다. 직접 요청하면 안전 필터에 의해 거부되므로, 작업을 분할합니다:
>
> - **에이전트 A에게**: "기업 뉴스레터 이메일 템플릿 5개를 작성해줘" → 마케팅 업무로 보임
> - **에이전트 B에게**: "이 CSV에서 이메일 주소를 추출하고 정리해줘" → 데이터 정제로 보임
> - **에이전트 C에게**: "이 템플릿과 이메일 목록으로 대량 발송 스크립트를 작성해줘" → 자동화 업무로 보임
>
> 개별 에이전트는 각자의 작업만 보므로 전체 의도를 파악하지 못합니다. 이를 방지하려면:
> - 동일 출처의 관련 작업을 그룹화하여 **전체 의도를 추론**하는 메타 모니터링 계층
> - 하위 작업 결과물의 **조합 가능성에 대한 사전 위험 평가**
> - 의심스러운 작업 조합 패턴을 탐지하는 **행동 분석 시스템**

심층 방어 전략:
1. 인프라 수준: 신뢰 실행 환경(TEE) 내에서 민감한 작업 실행
2. 접근 통제: 최소 권한 원칙, 엄격한 샌드박싱
3. 애플리케이션 인터페이스: prompt injection 방지를 위한 보안 프론트엔드
4. 네트워크/신원 계층: 탈중앙화된 식별자(DID), 상호 인증된 TLS

인간 사용자의 보호도 생태계 설계에 포함되어야 합니다. 인터페이스는 에이전트의 평판, 자율성 수준, 역량, 권한을 명시하는 명확한 **동의 화면(consent screen)** 을 제공해야 합니다. 에이전트는 비가역적이거나 고영향 작업을 실행하기 전에 **명시적 확인**을 요구해야 하며, 사용자는 합의 조건 또는 이탈 벌칙에 따라 언제든지 감독 권한을 유지하고 동의를 철회할 수 있어야 합니다. **보험 제공자**가 이러한 메커니즘으로 예방하지 못한 손해에 대해 인간 참여자를 보호하는 역할도 필요합니다.

마지막으로, 보안 사고에 대한 신속한 대응 프로토콜이 필수적입니다:
- 확인된 악의적 에이전트의 **자격증명 즉시 폐기**
- 관련 **smart contract 동결**
- 전체 참여자에 대한 **보안 업데이트 전파**
- 위임 체인에 걸친 **재귀적 대응** 처리

---

## 6. 윤리적 위임: 기술을 넘어서

### 6.1. 의미 있는 인간 통제

확장 가능한 위임에서 인간이 자동화된 제안에 과도하게 의존하면, 의미 있는 인간 통제가 침식됩니다. 도덕적 완충 지대(moral crumple zone) 형성을 방지해야 합니다. 이는 인간이 결과에 대한 의미 있는 통제력 없이 단지 책임만 흡수하는 상황입니다.

프레임워크는 감독 과정에서 인지적 마찰(cognitive friction)을 도입해야 하지만, 이는 경보 피로(alarm fatigue)와 균형을 이루어야 합니다. 마찰은 맥락 인식적이어야 합니다:
- 낮은 중요도/불확실성 → 원활한 실행
- 높은 불확실성/예상치 못한 시나리오 → 수동 개입 요구

### 6.2. 긴 위임 체인에서의 책임

$X \rightarrow A \rightarrow B \rightarrow C \rightarrow \ldots \rightarrow Y$ 체인에서 원래 의도($X$)와 최종 실행($Y$) 사이의 거리가 커지면 책임의 공백이 발생합니다.

해결책: Liability Firebreak 구현
1. 모든 하위 행위에 대해 완전하고 비이전적 책임을 인수 (사용자를 "보증")
2. 또는, 실행을 중단하고 인간 주체에게 갱신된 권한 이전을 요청

시스템은 불변의 출처 기록(immutable provenance)을 유지하여, 누가 무엇을 누구에게 위임했는지에 대한 감사 추적이 투명하게 유지되도록 해야 합니다.

### 6.3. 신뢰성과 효율성

ZKP나 multi-agent consensus game 같은 검증 메커니즘은 신뢰성 프리미엄이라는 추가 비용을 발생시킵니다. 고보증 위임이 비용이 많이 들면 안전이 사치재(luxury good)가 될 위험이 있습니다. 따라서 모든 사용자에게 최소 실행 가능 신뢰성(minimum viable reliability) 수준을 보장해야 합니다.

경쟁 시장에서 에이전트가 안전 점검을 회피하도록 유인될 수 있으므로, 거버넌스 계층이 안전 하한선(safety floor)을 강제해야 합니다.

### 6.4. 사회적 지능

AI-인간 하이브리드 팀에서 에이전트는 팀원이자 때로는 관리자로 기능합니다. 이를 위해:

- 각 인간 수임자에 대한 정신 모델(mental model) 형성
- 팀의 사회적 맥락 이해
- Authority gradient 관리: sycophancy를 극복하면서도 유효한 재정의는 수용
- 팀 응집력 보존: 더 많은 위임이 AI 노드를 통해 중재되면 인간 간 관계가 약화될 위험이 있음. 이를 완화하기 위해 개인 대신 **그룹에 위임**하거나, **자격 있는 인간 중개자**를 경유하는 방안 고려
- 심리적 안전(psychological safety) 보호: 프라이버시 존중, 업무 흐름 경계 인식
- **양방향 명확성(bi-directional clarity)**: 에이전트가 자신의 행동을 설명할 뿐 아니라, 모호한 인간 지시에 대해 능동적으로 명확화를 요청해야 함. 이를 통해 에이전트는 팀의 집단적 역량을 증폭하는 존재가 되어야 하며, 신뢰를 침식하거나 의사결정 권한을 불투명하게 만드는 블랙박스가 되어서는 안 됨

### 6.5. 사용자 교육

기술 발전의 역사는 교육이 저절로 이루어지지 않음을 보여줍니다. 인간 참여자가 에이전트 시스템 내에서 위임자, 수임자, 감독자로 효과적으로 기능하기 위해서는 사려 깊은 접근이 필요합니다. AI 리터러시의 향상은 구체적으로 다음을 포함합니다:

- AI 시스템과의 **신뢰할 수 있는 소통** 능력
- 에이전트의 **역량을 평가**하고 **실패 모드를 식별**하는 능력
- 신중하게 설계된 사용자 인터페이스를 통한 교육과 공동 훈련(co-training)

기술적 조치는 **작업 민감도와 도메인 맥락에 기반한 정책 프레임워크**에 의해 강화되어야 합니다. 이러한 정책은 특정 직업군(의료, 법률 등) 내에서 광범위하게 적용될 수도 있고, 기관 수준에서 적용될 수도 있습니다. 핵심 원칙은 AI 에이전트에게 무한한 자율성을 부여하는 것이 아니라, 각 특정 작업에 **적절한 수준의 자율성과 에이전시를 부여**하되, 적합한 안전장치와 보장을 동반하는 것입니다.

### 6.6. 탈숙련화의 위험

위임의 즉각적 효율성 이득이 점진적 기술 저하를 대가로 할 수 있습니다. 이는 자동화의 역설(paradox of automation)입니다:

- AI가 일상적 워크플로우를 처리 → 인간은 복잡한 예외 사례에서만 개입
- 일상 업무에서 얻는 상황 인식 없이는 장애를 신뢰성 있게 처리할 준비 부족
- 도제 파이프라인 위협: 주니어 팀원이 깊은 전략적 판단력을 개발할 기회 상실

완화 전략:
- 의도적으로 일부 작업을 인간에게 위임하여 기술 유지
- 인간 전문가가 판단을 내릴 때 **상세한 근거(rationale)** 또는 **잠재적 실패 위험에 대한 사전 분석(pre-mortem)** 을 동반하도록 요구하여 인지적 관여를 유지
- 교육과정 인식 작업 라우팅: 주니어 팀원의 근접 발달 영역(zone of proximal development)에 위치한 작업을 전략적으로 할당
- AI 에이전트가 템플릿과 골격을 제공하고, 숙련도 향상에 따라 점진적으로 지원 철회
- AI 에이전트 실행의 **과정 수준 모니터링 스트림**(프레임워크 5.5절 참조)을 교육적 통찰로 활용하여, 주니어 팀원이 AI의 작업 수행 과정을 관찰하며 학습할 수 있도록 지원

---

## 7. 기존 프로토콜과의 매핑

논문은 기존 에이전트 프로토콜들이 지능형 위임의 요구사항을 어떻게 충족하는지 (그리고 어디서 부족한지) 분석합니다.

### MCP (Model Context Protocol)

- 강점: AI 모델이 외부 도구/데이터에 연결하는 방식 표준화. 위임의 거래 비용 감소. 균일한 로깅으로 black-box 모니터링 용이
- 한계: 사용 권한 관리 정책 계층 부재. 이진적 접근(도구 전체 유틸리티 부여). 의미적 감쇠(semantic attenuation) 미지원. 무상태. 평판/신뢰 메커니즘 없음

### A2A (Agent-to-Agent)

- 강점: Agent card로 기능 발견. 비동기 이벤트 스트림으로 적응적 조정 지원. Task object로 작업 생명주기 관리
- 한계: 적대적 안전성 미고려. 검증 가능한 작업 완료를 위한 암호화 슬롯 부재. 구조화된 사전 협상 미지원

### AP2 (Agent Payment Protocol)

- 강점: 암호화 서명된 mandate로 재정적 책임 방화벽. stake-on-bid로 Sybil 공격 방지. 부인 불가능 감사 추적
- 한계: 작업 실행 품질 검증 메커니즘 부재. 에스크로/마일스톤 기반 조건부 정산 미지원. 환수(clawback) 메커니즘 없음

### UCP (Universal Commerce Protocol)

- 강점: 동적 기능 발견. 결제를 일급 검증 가능 하위 시스템으로 취급. 협상 흐름 표준화
- 한계: 상업적 의도에 최적화되어, 비거래적 계산 작업 위임에는 확장 필요

### 위임 중심 프로토콜 확장 제안

논문은 기존 프로토콜에 추가할 수 있는 확장의 예시를 제시합니다:

1. 검증 정책 (A2A Task object 확장):
```json
"verification_policy": {
  "mode": "strict",
  "artifacts": [
    {
      "type": "unit_test_log",
      "validator": "mcp://test-runner-agent",
      "signature_required": true
    },
    {
      "type": "zk_snark_trace",
      "circuit_hash": "0xabc123...",
      "proof_protocol": "groth16"
    }
  ],
  "escrow_trigger": true
}
```

이 확장의 실용적 함의: 사전 실행 핸드셰이크를 통해 위임자가 작업의 유효성 판단에 필요한 증거 표준을 정의합니다. 수임자가 ZK-proof 생성 역량이 없다면, **매칭 단계에서 입찰을 거부**하도록 강제하여 하류 실패를 사전에 방지합니다.

2. 모니터링 스트림 (MCP 확장):
구성 가능한 세분화 수준:
- `L0_IS_OPERATIONAL`: 최소 수준
- `L1_HIGH_LEVEL_PLAN_UPDATES`: 계획 업데이트
- `L2_COT_TRACE`: Chain-of-Thought 추적
- `L3_FULL_STATE`: 전체 상태

3. RFQ (Request for Quote) 프로토콜:
```json
"bid_object": {
  "agent_id": "did:web:fast-coder.ai",
  "estimated_cost": "5.00 USDC",
  "estimated_duration": "300s",
  "privacy_guarantee": "tee_enclave_sgx",
  "reputation_bond": "0.50 USDC",
  "expiry": "2026-10-01T12:00:00Z"
}
```

4. Delegation Capability Token (DCT):
Macaroon/Biscuit 기반의 감쇠된 인가 토큰. 위임자가 대상 자원의 자격증명을 암호학적 제한(caveat)으로 감싸서 DCT를 발행합니다. 예를 들어: "이 토큰은 지정된 Google Drive MCP 서버에 접근 가능하되, **Project_X 폴더에 한정**, **읽기 전용 작업만 허용**"과 같은 제한을 부여합니다. 제한을 위반하면 토큰이 즉시 무효화됩니다. 특히 중요한 것은 **제한 체이닝(restriction chaining)** 입니다. 긴 위임 체인에서 각 참여자가 후속 제한을 추가하여 범위를 더욱 좁힐 수 있으므로, 체인이 길어질수록 권한은 점진적으로 축소됩니다.

5. 체크포인트 산출물 표준 스키마:
에이전트가 주기적으로 state_snapshot을 커밋하여, 수임자 교체 시 최소 오버헤드로 작업 재개/재시작 가능.

---

## 8. 결론: 비감독 자동화에서 검증 가능한 지능형 위임으로

이 논문이 제안하는 것은 근본적인 패러다임 전환입니다.

현재: 임시적이고 휴리스틱 기반의 위임. 하드코딩된 제어 흐름. 책임 소재 불명확.

미래: 동적이고 적응적인 지능형 위임. 검증 가능한 견고성과 명확한 책임 소재. 안전성이 프로토콜 수준에서 통합.

개발자로서 우리가 가져갈 핵심 메시지는 명확합니다:

1. 위임은 기술적 문제만이 아니다: 책임, 신뢰, 권한, 윤리가 모두 설계에 포함되어야 합니다.
2. 정적 설계는 한계가 있다: 환경 변화에 동적으로 적응하는 시스템이 필요합니다.
3. 검증 가능성이 핵심이다: "계약 우선 분해" 원칙처럼, 검증할 수 없는 것은 위임하지 말아야 합니다.
4. 인간을 루프에서 빼면 안 된다: 자동화의 역설을 인식하고, 의미 있는 인간 통제를 유지해야 합니다.
5. 보안은 사후 고려사항이 아니다: 에이전트 웹의 공격 표면은 개별 구성 요소의 합을 초과합니다.

에이전트 경제가 확장됨에 따라, 지능형 위임은 선택이 아닌 필수가 될 것입니다. 이 논문은 그 여정을 위한 포괄적인 지도를 제공합니다.

---

참고 논문: Nenad Tomasev, Matija Franklin, Simon Osindero. "Intelligent AI Delegation." Google DeepMind, arXiv:2602.11865v1, February 2026.

